import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from bs4 import BeautifulSoup
import re
import openai
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import cosine_similarity

# === Prosta autoryzacja uÅ¼ytkownikÃ³w ===
def check_password():
    def password_entered():
        if st.session_state["password"] == st.secrets["APP_PASSWORD"]:
            st.session_state["password_correct"] = True
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.text_input("ğŸ” Podaj hasÅ‚o", type="password", on_change=password_entered, key="password")
        st.stop()
    elif not st.session_state["password_correct"]:
        st.text_input("ğŸ” Podaj hasÅ‚o", type="password", on_change=password_entered, key="password")
        st.error("âŒ NieprawidÅ‚owe hasÅ‚o")
        st.stop()

# Uruchom logowanie przed caÅ‚Ä… aplikacjÄ…
check_password()

# === Ustawienia API ===
openai.api_key = st.secrets.get("OPENAI_API_KEY") or st.text_input("ğŸ”‘ Podaj swÃ³j OpenAI API Key:", type="password")

# === Ustawienia aplikacji ===
st.set_page_config(page_title="Semantic SEO Toolkit", layout="wide")

# === Sidebar ===
st.sidebar.title("ğŸ” Wybierz funkcjÄ™")
view = st.sidebar.radio("DostÄ™pne analizy:", [
    "ğŸ“Š SiteRadius & SiteFocus",
    "ğŸ“Œ Outliery tematyczne",
    "ğŸ”— Linkowanie wewnÄ™trzne",
    "ğŸš§ Content Gap",
    "ğŸ“ˆ Monitoring w czasie",
    "âš”ï¸ PorÃ³wnanie z konkurencjÄ…"
])

# === WspÃ³lne funkcje ===
def clean_text(text):
    soup = BeautifulSoup(text, "html.parser")
    text = soup.get_text(separator=" ")
    text = re.sub(r"[*_~#>`]", "", text)
    text = re.sub(r"\[(.*?)\]\(.*?\)", r"\1", text)
    text = re.sub(r"https?://\S+", "", text)
    text = re.sub(r"[^\w\s.,!?-]", "", text)
    return text.strip()

def get_embedding(text):
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def compute_metrics(embeddings, custom_centroid=None):
    sim_matrix = cosine_similarity(embeddings)
    np.fill_diagonal(sim_matrix, np.nan)
    site_focus = np.nanmean(sim_matrix)
    centroid = np.mean(embeddings, axis=0) if custom_centroid is None else custom_centroid
    dists = np.linalg.norm(embeddings - centroid, axis=1)
    site_radius = np.max(dists)
    return site_focus, site_radius, dists, centroid

# === Widoki ===
if view == "ğŸ“Š SiteRadius & SiteFocus":
    st.title("ğŸ“Š SiteRadius & SiteFocus")
    st.info("Tutaj moÅ¼esz analizowaÄ‡ rozrzut i spÃ³jnoÅ›Ä‡ tematycznÄ… treÅ›ci jednej lub wielu domen.")

    uploaded_file = st.file_uploader("ğŸ“ Wgraj plik CSV (kolumny: URL, title, content)", type="csv")
    topic_input = st.text_input("ğŸ¯ (Opcjonalnie) WprowadÅº temat gÅ‚Ã³wny strony lub bloga:")

    if uploaded_file and openai.api_key:
        df = pd.read_csv(uploaded_file, sep=None, engine="python")
        if not {'URL', 'title', 'content'}.issubset(df.columns):
            st.error("âš ï¸ Plik musi zawieraÄ‡ kolumny: URL, title, content.")
        else:
            df["clean_text"] = df["content"].astype(str).apply(clean_text)
            df["embedding"] = df["clean_text"].apply(get_embedding)
            embeddings = np.vstack(df["embedding"].tolist())

            centroid_vector = get_embedding(topic_input) if topic_input else None
            site_focus, site_radius, dists, centroid = compute_metrics(embeddings, centroid_vector)

            tsne = TSNE(n_components=2, perplexity=5, random_state=42)
            coords = tsne.fit_transform(embeddings)

            df["x"] = coords[:, 0]
            df["y"] = coords[:, 1]
            df["dist_to_center"] = dists

            st.subheader("ğŸ“ˆ Wyniki analizy")
            st.metric("SiteFocus (spÃ³jnoÅ›Ä‡)", f"{site_focus:.4f}")
            st.metric("SiteRadius (rozrzut)", f"{site_radius:.4f}")

            fig, ax = plt.subplots(figsize=(10, 7))
            ax.scatter(df["x"], df["y"], s=50, alpha=0.8, edgecolor='k')

            tsne_centroid = TSNE(n_components=2, perplexity=5, random_state=42).fit_transform(np.vstack([centroid, embeddings]))
            cx, cy = tsne_centroid[0]
            ax.scatter(cx, cy, marker='X', s=200, color='blue', edgecolor='black', label="Centrum tematyczne")

            ax.set_title("t-SNE mapa tematyczna")
            ax.set_xlabel("x")
            ax.set_ylabel("y")
            ax.legend()
            st.pyplot(fig)

            st.subheader("ğŸ” Wpisy (z odlegÅ‚oÅ›ciÄ… od Å›rodka)")
            st.dataframe(df[["title", "URL", "dist_to_center"]].sort_values("dist_to_center", ascending=False))

elif view == "ğŸ“Œ Outliery tematyczne":
    st.title("ğŸ“Œ Wykrywanie outlierÃ³w")
    st.info("ZnajdÅº wpisy blogowe, ktÃ³re tematycznie odbiegajÄ… od reszty Twojej zawartoÅ›ci.")

    uploaded_file = st.file_uploader("ğŸ“ Wgraj plik CSV z wpisami (URL, title, content)", type="csv", key="outliers")
    threshold = st.slider("ğŸ“ PrÃ³g odlegÅ‚oÅ›ci od Å›rodka (np. 95 percentyl):", 50, 99, 95)

    if uploaded_file and openai.api_key:
        df = pd.read_csv(uploaded_file, sep=None, engine="python")
        if not {'URL', 'title', 'content'}.issubset(df.columns):
            st.error("âš ï¸ Plik musi zawieraÄ‡ kolumny: URL, title, content.")
        else:
            df["clean_text"] = df["content"].astype(str).apply(clean_text)
            df["embedding"] = df["clean_text"].apply(get_embedding)
            embeddings = np.vstack(df["embedding"].tolist())

            _, _, dists, centroid = compute_metrics(embeddings)
            df["dist_to_center"] = dists

            perc_val = np.percentile(dists, threshold)
            outliers_df = df[df["dist_to_center"] > perc_val].sort_values("dist_to_center", ascending=False)

            st.subheader(f"ğŸš¨ Wpisy uznane za outliery (>{threshold} percentyl)")
            st.dataframe(outliers_df[["title", "URL", "dist_to_center"]])

elif view == "ğŸ”— Linkowanie wewnÄ™trzne":
    st.title("ğŸ”— Semantyczne linkowanie wewnÄ™trzne")
    st.info("Generuj linki wewnÄ™trzne miÄ™dzy tematycznie najbliÅ¼szymi wpisami.")

    uploaded_file = st.file_uploader("ğŸ“ Wgraj plik CSV z wpisami (URL, title, content)", type="csv", key="linking")
    top_n_links = st.slider("ğŸ”— Liczba sugerowanych linkÃ³w na wpis:", 1, 5, 3)

    if uploaded_file and openai.api_key:
        df = pd.read_csv(uploaded_file, sep=None, engine="python")
        if not {'URL', 'title', 'content'}.issubset(df.columns):
            st.error("âš ï¸ Plik musi zawieraÄ‡ kolumny: URL, title, content.")
        else:
            df["clean_text"] = df["content"].astype(str).apply(clean_text)
            df["embedding"] = df["clean_text"].apply(get_embedding)
            embeddings = np.vstack(df["embedding"].tolist())

            sim_matrix = cosine_similarity(embeddings)
            np.fill_diagonal(sim_matrix, -np.inf)

            suggestions = []
            for i in range(len(df)):
                similar_idx = np.argsort(sim_matrix[i])[::-1][:top_n_links]
                suggested_links = [(df.iloc[j]["title"], df.iloc[j]["URL"]) for j in similar_idx]
                suggestions.append(suggested_links)

            df["link_suggestions"] = suggestions

            st.subheader("ğŸ”— Propozycje linkowania")
            for _, row in df.iterrows():
                st.markdown(f"**{row['title']}**  ")
                for link_title, link_url in row["link_suggestions"]:
                    st.markdown(f"â†’ [{link_title}]({link_url})")
                st.markdown("---")

elif view == "ğŸš§ Content Gap":
    st.title("ğŸš§ Content Gap Analysis")
    st.info("PorÃ³wnaj swojÄ… treÅ›Ä‡ z konkurencjÄ… i wykryj luki tematyczne.")

    user_file = st.file_uploader("ğŸ“ Wgraj swojÄ… treÅ›Ä‡ (CSV: URL, title, content)", type="csv", key="gap_user")
    comp_file = st.file_uploader("ğŸ“ Wgraj treÅ›Ä‡ konkurencji (CSV: URL, title, content)", type="csv", key="gap_comp")
    similarity_threshold = st.slider("ğŸ¯ PrÃ³g podobieÅ„stwa (cosine)", 0.0, 1.0, 0.75, step=0.01)

    if user_file and comp_file and openai.api_key:
        df_user = pd.read_csv(user_file, sep=None, engine="python")
        df_comp = pd.read_csv(comp_file, sep=None, engine="python")

        if not {'URL', 'title', 'content'}.issubset(df_user.columns.union(df_comp.columns)):
            st.error("âš ï¸ Oba pliki muszÄ… zawieraÄ‡ kolumny: URL, title, content.")
        else:
            df_user["clean_text"] = df_user["content"].astype(str).apply(clean_text)
            df_user["embedding"] = df_user["clean_text"].apply(get_embedding)
            emb_user = np.vstack(df_user["embedding"].tolist())

            df_comp["clean_text"] = df_comp["content"].astype(str).apply(clean_text)
            df_comp["embedding"] = df_comp["clean_text"].apply(get_embedding)
            emb_comp = np.vstack(df_comp["embedding"].tolist())

            sim_matrix = cosine_similarity(emb_comp, emb_user)
            max_similarities = np.max(sim_matrix, axis=1)
            df_comp["max_similarity"] = max_similarities

            gaps_df = df_comp[df_comp["max_similarity"] < similarity_threshold].sort_values("max_similarity")

            st.subheader("ğŸš§ Wykryte luki tematyczne wzglÄ™dem Twojej treÅ›ci")
            st.dataframe(gaps_df[["title", "URL", "max_similarity"]])

elif view == "ğŸ“ˆ Monitoring w czasie":
    st.title("ğŸ“ˆ Monitoring tematyczny w czasie")
    st.info("Obserwuj, jak zmienia siÄ™ spÃ³jnoÅ›Ä‡ i zakres tematyczny Twojej witryny w kolejnych okresach.")

    uploaded_files = st.file_uploader("ğŸ“ Wgraj pliki CSV z okresÃ³w (np. Q1.csv, Q2.csv...)", accept_multiple_files=True, type="csv")

    if uploaded_files and openai.api_key:
        focus_results = []
        radius_results = []
        periods = []

        for file in uploaded_files:
            df = pd.read_csv(file, sep=None, engine="python")
            if not {'URL', 'title', 'content'}.issubset(df.columns):
                st.warning(f"âš ï¸ PominiÄ™to plik {file.name} â€” brak wymaganych kolumn.")
                continue

            df["clean_text"] = df["content"].astype(str).apply(clean_text)
            df["embedding"] = df["clean_text"].apply(get_embedding)
            embeddings = np.vstack(df["embedding"].tolist())

            focus, radius, _, _ = compute_metrics(embeddings)
            periods.append(file.name)
            focus_results.append(focus)
            radius_results.append(radius)

        if focus_results:
            result_df = pd.DataFrame({
                "Okres": periods,
                "SiteFocus": focus_results,
                "SiteRadius": radius_results
            })

            st.subheader("ğŸ“Š Zmiany wartoÅ›ci SiteFocus i SiteRadius")
            st.line_chart(result_df.set_index("Okres"))
            st.dataframe(result_df)

elif view == "âš”ï¸ PorÃ³wnanie z konkurencjÄ…":
    st.title("âš”ï¸ PorÃ³wnanie strategii treÅ›ci")
    st.info("Zobacz jak wypadasz na tle konkurencji pod wzglÄ™dem spÃ³jnoÅ›ci i rozrzutu tematycznego.")

    uploaded_files = st.file_uploader(
        "ğŸ“ Wgraj pliki CSV (Twoja domena + konkurencja, z kolumnÄ… 'Domena')",
        accept_multiple_files=True,
        type="csv"
    )

    if uploaded_files and openai.api_key:
        results = []

        for file in uploaded_files:
            df = pd.read_csv(file, sep=None, engine="python")
            if not {'URL', 'title', 'content', 'Domena'}.issubset(df.columns):
                st.warning(f"âš ï¸ PominiÄ™to plik {file.name} â€” brak wymaganych kolumn.")
                continue

            for domain_name, group in df.groupby("Domena"):
                group["clean_text"] = group["content"].astype(str).apply(clean_text)
                group["embedding"] = group["clean_text"].apply(get_embedding)
                embeddings = np.vstack(group["embedding"].tolist())
                focus, radius, _, _ = compute_metrics(embeddings)
                results.append({"Domena": domain_name, "SiteFocus": focus, "SiteRadius": radius})

        if results:
            results_df = pd.DataFrame(results).sort_values("SiteFocus", ascending=False)

            st.subheader("ğŸ“‹ PorÃ³wnanie domen")

            # Filtry interaktywne
            selected_domains = st.multiselect("ğŸ” Wybierz domeny do porÃ³wnania:", options=results_df["Domena"].unique(), default=list(results_df["Domena"].unique()))
            focus_range = st.slider("ğŸ¯ Zakres SiteFocus:", float(results_df["SiteFocus"].min()), float(results_df["SiteFocus"].max()), (float(results_df["SiteFocus"].min()), float(results_df["SiteFocus"].max())))
            radius_range = st.slider("ğŸ“ Zakres SiteRadius:", float(results_df["SiteRadius"].min()), float(results_df["SiteRadius"].max()), (float(results_df["SiteRadius"].min()), float(results_df["SiteRadius"].max())))

            filtered_df = results_df[
                (results_df["Domena"].isin(selected_domains)) &
                (results_df["SiteFocus"].between(*focus_range)) &
                (results_df["SiteRadius"].between(*radius_range))
            ]

            st.dataframe(filtered_df)

            import matplotlib.pyplot as plt
            import seaborn as sns

            fig, ax = plt.subplots(figsize=(10, 5))
            bar_width = 0.35
            x = np.arange(len(filtered_df))

            ax.bar(x - bar_width/2, filtered_df["SiteFocus"], width=bar_width, label="SiteFocus", color="#1f77b4")
            ax.bar(x + bar_width/2, filtered_df["SiteRadius"], width=bar_width, label="SiteRadius", color="#aec7e8")

            ax.set_xticks(x)
            ax.set_xticklabels(filtered_df["Domena"], rotation=45, ha="right")
            ax.set_ylabel("WartoÅ›ci")
            ax.set_title("PorÃ³wnanie SiteFocus i SiteRadius")
            ax.legend()
            st.pyplot(fig)

            st.download_button(
                label="â¬‡ï¸ Pobierz dane jako CSV",
                data=filtered_df.to_csv(index=False).encode('utf-8'),
                file_name="porownanie_domen.csv",
                mime="text/csv"
            )

            export_pdf = st.checkbox("ğŸ“„ Wygeneruj PDF (eksperymentalne)")
            if export_pdf:
                import io
                from fpdf import FPDF

                pdf_buf = io.BytesIO()
                fig.savefig(pdf_buf, format="png")
                pdf_buf.seek(0)

                pdf = FPDF()
                pdf.add_page()
                pdf.set_font("Arial", size=12)
                pdf.cell(200, 10, txt="PorÃ³wnanie domen - Semantic SEO", ln=True, align="C")
                pdf.image(pdf_buf, x=10, y=30, w=180)

                pdf_output = io.BytesIO()
                pdf.output(pdf_output)
                pdf_output.seek(0)

                st.download_button(
                    label="ğŸ“¥ Pobierz PDF",
                    data=pdf_output,
                    file_name="porownanie_domen.pdf",
                    mime="application/pdf"
                )
